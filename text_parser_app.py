import streamlit as st
import pandas as pd
import re
from io import StringIO, BytesIO
import plotly.express as px
import openpyxl
import numpy as np

st.set_page_config(layout="wide", page_title="–ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –¥–∞–Ω–∏—Ö –∑ —Ç–µ–∫—Å—Ç—É", page_icon="üìù")

st.title("üìù –ê–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –¥–∞–Ω–∏—Ö –∑ —Ç–µ–∫—Å—Ç—É")

st.markdown("""
    –¶—è –ø—Ä–æ–≥—Ä–∞–º–∞ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö –∑ –∑–∞—è–≤–æ–∫, —Å–∫–æ–ø—ñ–π–æ–≤–∞–Ω–∏—Ö
    –ø—Ä—è–º–æ –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏.

    **–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è:**
    1. –ü–µ—Ä–µ–π–¥—ñ—Ç—å –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫—É –∑ –¥–∞–Ω–∏–º–∏ –∑–∞—è–≤–æ–∫.
    2. –í–∏–¥—ñ–ª—ñ—Ç—å –≤–µ—Å—å –≤–º—ñ—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –Ω–∞—Ç–∏—Å–Ω—É–≤—à–∏ **`Ctrl+A`**).
    3. –°–∫–æ–ø—ñ—é–π—Ç–µ –≤–∏–¥—ñ–ª–µ–Ω–∏–π –≤–º—ñ—Å—Ç —É –±—É—Ñ–µ—Ä –æ–±–º—ñ–Ω—É (**`Ctrl+C`**).
    4. –í—Å—Ç–∞–≤—Ç–µ —Ç–µ–∫—Å—Ç —É –ø–æ–ª–µ –Ω–∏–∂—á–µ (**`Ctrl+V`**).

    –ü—Ä–æ–≥—Ä–∞–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞—î —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É—î –¥–∞–Ω—ñ —É —Ç–∞–±–ª–∏—Ü—é –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
""")


# --- –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó —Ç–µ–∫—Å—Ç—É —á–∞—Å—É –≤ —Ö–≤–∏–ª–∏–Ω–∏ ---
def convert_downtime_to_minutes(downtime_text):
    if not isinstance(downtime_text, str) or downtime_text.strip() == "":
        return np.nan
    
    total_minutes = 0
    days = re.search(r'(\d+)\s*–¥–µ–Ω—å', downtime_text)
    hours = re.search(r'(\d+)\s*–≥–æ–¥', downtime_text)
    minutes = re.search(r'(\d+)\s*—Ö–≤', downtime_text)
    
    if days:
        total_minutes += int(days.group(1)) * 24 * 60
    if hours:
        total_minutes += int(hours.group(1)) * 60
    if minutes:
        total_minutes += int(minutes.group(1))
        
    return total_minutes

# --- –û–Ω–æ–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è-–ø–∞—Ä—Å–µ—Ä –¥–ª—è –≤—Å—Ç–∞–≤–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö ---
def parse_pasted_data(text_data):
    """
    –†–æ–∑–±–∏—Ä–∞—î –≤—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç, –≤–∏—Ç—è–≥–∞—é—á–∏ –¥–∞–Ω—ñ –∑ –∫–æ–∂–Ω–æ—ó –∑–∞—è–≤–∫–∏.
    """
    records = re.split(r'(A-\d{6,})', text_data)
    records = [records[i] + records[i+1] for i in range(1, len(records), 2)]

    parsed_data = []

    for record in records:
        record = record.replace('\n', '')

        # ID
        id_match = re.search(r'^(A-\d{6,})', record)
        if not id_match:
            continue
        id_val = id_match.group(1)
        remaining_text = record[len(id_val):].strip()

        # –í–∏–¥ –∑–∞—è–≤–∫–∏ —Ç–∞ –°—Ç–∞—Ç—É—Å
        status_keywords = "(?:-–í—ñ–¥–º—ñ–Ω–µ–Ω–æ|-–í—ñ–¥—Ö–∏–ª–µ–Ω–æ|–í–∏–∫–æ–Ω–∞–Ω–æ|–ß–µ–∫–∞—î –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è|–í —Ä–æ–±–æ—Ç—ñ)"
        match_type_status = re.search(r'^(.*?)' + status_keywords, remaining_text)
        type_val = ""
        status_val = ""
        if match_type_status:
            type_val = match_type_status.group(1).strip()
            if type_val.startswith("–ü—Ä–æ—Å—Ç—ñ–π –†–¶"): type_val = "–ü—Ä–æ—Å—Ç—ñ–π –†–¶"
            elif type_val.startswith("–ü—Ä–æ—Å—Ç—ñ–π"): type_val = "–ü—Ä–æ—Å—Ç—ñ–π"
            remaining_text = remaining_text[len(match_type_status.group(0)):].strip()
            status_match = re.search(status_keywords, match_type_status.group(0))
            status_val = status_match.group(0).strip() if status_match else ""
        else:
            match_type_status = re.search(r'^(.*?)(\d{2}\.\d{2}\.\d{4},\s\d{2}:\d{2})', remaining_text)
            if match_type_status:
                type_val = match_type_status.group(1).strip()
                remaining_text = remaining_text[len(match_type_status.group(1)):].strip()

        # –î–∞—Ç–∞ —ñ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è
        date_time_exec_val = ""
        date_time_exec_match = re.search(r'(\d{2}\.\d{2}\.\d{4},\s\d{2}:\d{2})', remaining_text)
        if date_time_exec_match:
            date_time_exec_val = date_time_exec_match.group(1)
            remaining_text = remaining_text[date_time_exec_match.end():].strip()

        # –ü—Ä–æ—Å—Ç—ñ–π
        downtime_val = ""
        downtime_match = re.search(r'(?:-[\d\s\w]+—Ö–≤)?\s*?([\d\s\w]+—Ö–≤)', remaining_text)
        if downtime_match:
            downtime_val = downtime_match.group(1).strip()
            remaining_text = remaining_text[downtime_match.end():].strip()
        else:
            downtime_match = re.search(r'(-[\d\s\w]+—Ö–≤)-', remaining_text)
            if downtime_match:
                downtime_val = downtime_match.group(1).strip()
                remaining_text = remaining_text[downtime_match.end():].strip()
        
        # –†–µ—à—Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
        description_val = ""
        report_val = ""
        —Ü–µ—Ö_val = ""
        department_val = ""
        line_val = ""
        equipment_val = ""
        date_time_create_val = ""
        author_val = ""
        service_val = ""
        executor_val = ""
        
        middle_part_match = re.search(r'(.*?)(–¶–µ—Ö|–ö—É–ª—ñ–Ω–∞—Ä–Ω–∏–π —Ü–µ—Ö)', remaining_text, re.IGNORECASE)
        if middle_part_match:
            middle_part = middle_part_match.group(1)
            
            report_keywords = "–†–µ–≤—ñ–∑—ñ—è|–ó–∞–º—ñ–Ω–∞|–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è|–£—Å—É–Ω–µ–Ω–æ|–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞|–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è|–ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–∏–ª–∏|–í–∏–¥–∞–ª–µ–Ω–Ω—è|–ó–º–∞—â–µ–Ω–Ω—è|–ü–æ—à—É–∫|–ü–µ—Ä–µ—Ä–æ–±–ª–µ–Ω–æ|–ü–æ–º—ñ—á|–î–æ–ø–æ–º–æ–≥–∞"
            report_match = re.search(report_keywords, middle_part)
            if report_match:
                description_val = middle_part[:report_match.start()].strip()
                report_val = middle_part[report_match.start():].strip()
            else:
                description_val = middle_part.strip()
                report_val = ""

            —Ü–µ—Ö_match = re.search(r'(–¶–µ—Ö [^\s]+|–ö—É–ª—ñ–Ω–∞—Ä–Ω–∏–π —Ü–µ—Ö)', remaining_text)
            —Ü–µ—Ö_val = —Ü–µ—Ö_match.group(0).strip() if —Ü–µ—Ö_match else ""
            
            department_match = re.search(r'(–î—ñ–ª—å–Ω–∏—Ü—è [^\s]+(?: [^\s]+)*)', remaining_text)
            department_val = department_match.group(0).strip() if department_match else ""
            
            line_match = re.search(r'(–õ—ñ–Ω—ñ—è [^\s]+(?: [^\s]+)*)', remaining_text)
            line_val = line_match.group(0).strip() if line_match else ""

            equipment_match = re.search(r'(–ú–∞—à–∏–Ω–∞|–ú–µ—Ç–∞–ª–æ–¥–µ—Ç–µ–∫—Ç–æ—Ä|–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–µ—Ä|–ü–∞–∫—É–≤–∞–ª—å–Ω–∞ –º–∞—à–∏–Ω–∞|–ö–ª—ñ–ø—Å–∞—Ç–æ—Ä|–ö–æ–Ω–≤–µ—î—Ä|–í–∞–≥–∏)[^,]+', remaining_text)
            equipment_val = equipment_match.group(0).strip() if equipment_match else ""
            
            date_time_create_match = re.search(r'(\d{2}\.\d{2}\.\d{4},\s\d{2}:\d{2})', record)
            date_time_create_val = date_time_create_match.group(1) if date_time_create_match else ""
            
            author_match = re.search(r'(\d{2}:\d{2})([\s–ê-–Ø–Ü–Ñ–á“ê][–∞-—è—ñ—ó—î“ë]+(?:\s[–ê-–Ø–Ü–Ñ–á“ê][–∞-—è—ñ—ó—î“ë]+)?)', record)
            author_val = author_match.group(2).strip() if author_match else ""
            
            service_match = re.search(r'(–°–ª—É–∂–±–∞ –∑ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–æ–≤–∞–Ω–∏—Ö —Å–∏—Å—Ç–µ–º –∫–µ—Ä—É–≤–∞–Ω–Ω—è –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–æ–º|–°–ª—É–∂–±–∞ —Ä–µ–º–æ–Ω—Ç—É –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è)', record)
            service_val = service_match.group(0).strip() if service_match else ""

            executor_match = re.search(r'(?:–°–ª—É–∂–±–∏?.*?)(\s*[–ê-–Ø–Ü–Ñ–á“ê][–∞-—è—ñ—ó—î“ë]+(?:\s+[–ê-–Ø–Ü–Ñ–á“ê][–∞-—è—ñ—ó—î“ë]+)*)', remaining_text)
            executor_val = executor_match.group(1).strip() if executor_match else ""
        
        parsed_data.append({
            "–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä": id_val,
            "–í–∏–¥ –∑–∞—è–≤–∫–∏": type_val,
            "–î–∞—Ç–∞ —ñ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è": date_time_exec_val,
            "–°—Ç–∞—Ç—É—Å": status_val,
            "–û–ø–∏—Å": description_val,
            "–ó–≤—ñ—Ç –≤–∏–∫–æ–Ω–∞–Ω–Ω—è": report_val,
            "–ü—Ä–æ—Å—Ç—ñ–π (—Ç–µ–∫—Å—Ç)": downtime_val,
            "–¶–µ—Ö": —Ü–µ—Ö_val,
            "–î—ñ–ª—å–Ω–∏—Ü—è": department_val,
            "–õ—ñ–Ω—ñ—è": line_val,
            "–û–±–ª–∞–¥–Ω–∞–Ω–Ω—è": equipment_val,
            "–î–∞—Ç–∞ —ñ —á–∞—Å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è": date_time_create_val,
            "–ê–≤—Ç–æ—Ä": author_val,
            "–°–ª—É–∂–±–∞": service_val,
            "–í–∏–∫–æ–Ω–∞–≤–µ—Ü—å": executor_val,
        })

    return pd.DataFrame(parsed_data)


# --- –û—Å–Ω–æ–≤–Ω–∏–π —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
pasted_data = st.text_area("üìã –í—Å—Ç–∞–≤—Ç–µ –¥–∞–Ω—ñ —Å—é–¥–∏", height=300, help="–í–∏–¥—ñ–ª—ñ—Ç—å —ñ —Å–∫–æ–ø—ñ—é–π—Ç–µ –¥–∞–Ω—ñ –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏, –∞ –ø–æ—Ç—ñ–º –≤—Å—Ç–∞–≤—Ç–µ —Å—é–¥–∏.")

if pasted_data:
    try:
        df = parse_pasted_data(pasted_data)
        
        if df.empty:
            st.warning("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –∂–æ–¥–Ω–æ—ó –∑–∞—è–≤–∫–∏. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –¥–∞–Ω—ñ —Å–∫–æ–ø—ñ–π–æ–≤–∞–Ω—ñ –ø—Ä–∞–≤–∏–ª—å–Ω–æ.")
        else:
            st.success(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ {len(df)} –∑–∞—è–≤–æ–∫.")

            # --- –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ (–≤—Å—ñ—Ö –∑–∞—è–≤–æ–∫) ---
            st.subheader("üìã –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü—è")
            st.dataframe(df, use_container_width=True)

            # --- –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∑–∞—è–≤–æ–∫ –∑—ñ —Å—Ç–∞—Ç—É—Å–æ–º "–í–∏–∫–æ–Ω–∞–Ω–æ" ---
            st.subheader("üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ –¥–∞–Ω–∏—Ö (—Ç—ñ–ª—å–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω—ñ –∑–∞—è–≤–∫–∏)")
            
            df_executed = df[df['–°—Ç–∞—Ç—É—Å'] == '–í–∏–∫–æ–Ω–∞–Ω–æ'].copy()
            
            if not df_executed.empty:
                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —á–∏—Å–ª–æ–≤–æ–≥–æ —Å—Ç–æ–≤–ø—Ü—è –∑ –ø—Ä–æ—Å—Ç–æ—î–º –≤ —Ö–≤–∏–ª–∏–Ω–∞—Ö
                df_executed['–ü—Ä–æ—Å—Ç—ñ–π (—Ö–≤)'] = df_executed['–ü—Ä–æ—Å—Ç—ñ–π (—Ç–µ–∫—Å—Ç)'].apply(convert_downtime_to_minutes)
                
                avg_downtime = df_executed['–ü—Ä–æ—Å—Ç—ñ–π (—Ö–≤)'].mean()
                if pd.notna(avg_downtime):
                    st.metric("–°–µ—Ä–µ–¥–Ω—ñ–π —á–∞—Å –ø—Ä–æ—Å—Ç–æ—é", f"{avg_downtime:.1f} —Ö–≤")
                else:
                    st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ —á–∞—Å—É –ø—Ä–æ—Å—Ç–æ—é.")
            else:
                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏ (–Ω–µ–º–∞—î –≤–∏–∫–æ–Ω–∞–Ω–∏—Ö –∑–∞—è–≤–æ–∫).")
            
            # –ì—Ä–∞—Ñ—ñ–∫ –∑–∞—è–≤–æ–∫ –ø–æ —Ü–µ—Ö–∞—Ö
            if '–¶–µ—Ö' in df_executed.columns:
                department_counts = df_executed['–¶–µ—Ö'].value_counts().reset_index()
                if not department_counts.empty:
                    fig_departments = px.bar(
                        department_counts, 
                        x='–¶–µ—Ö', 
                        y='count',
                        title='–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞—è–≤–æ–∫ –ø–æ —Ü–µ—Ö–∞—Ö (—Ç—ñ–ª—å–∫–∏ –≤–∏–∫–æ–Ω–∞–Ω—ñ)',
                        labels={'count': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞—è–≤–æ–∫'}
                    )
                    st.plotly_chart(fig_departments, use_container_width=True)
            
            # --- –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ---
            @st.cache_data
            def convert_df_to_excel(df_to_convert):
                output = BytesIO()
                df_to_convert.to_excel(output, index=False, engine='openpyxl')
                processed_data = output.getvalue()
                return processed_data

            st.download_button(
                label="‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ —è–∫ Excel",
                data=convert_df_to_excel(df),
                file_name=f'–∞–Ω–∞–ª—ñ–∑_–∑–∞—è–≤–æ–∫_–∑_—Ç–µ–∫—Å—Ç—É_{pd.Timestamp.now().strftime("%Y-%m-%d")}.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                help='–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –æ–±—Ä–æ–±–ª–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é —É —Ñ–æ—Ä–º–∞—Ç—ñ Excel'
            )

    except Exception as e:
        st.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}")
        st.info("–ë—É–¥—å –ª–∞—Å–∫–∞, –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ —Ñ–æ—Ä–º–∞—Ç –≤—Å—Ç–∞–≤–ª–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ø—Ä–∏–∫–ª–∞–¥—É.")
else:
    st.info("‚¨ÜÔ∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –≤—Å—Ç–∞–≤—Ç–µ –¥–∞–Ω—ñ, —â–æ–± —Ä–æ–∑–ø–æ—á–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑.")
